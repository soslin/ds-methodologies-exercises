{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanoslin/codeup-data-science/ds-methodologies-exercises/nlp/acquire.py:21: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 21 of the file /Users/seanoslin/codeup-data-science/ds-methodologies-exercises/nlp/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.content)\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \"\"\"\n",
    "    Lowercase the string\n",
    "    Normalize unicode characters\n",
    "    Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    \"\"\"\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "     # remove anything not a space character, an apostrophy, letter, or number\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    string = string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(s, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "{'context': \"codeup's data science program wa created in response to a \"\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': \"codeup's data science program teach hand on skill using \"\n",
      "                'python and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'context': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "pprint(documents)\n",
    "\n",
    "print('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: lemmatize(basic_clean(documents[topic])) for topic in documents}\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idf\n",
       "word        \n",
       "teach    3.0\n",
       "created  3.0\n",
       "hand     3.0\n",
       "skill    3.0\n",
       "using    3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple way to calculate idf for demonstration. Note that this\n",
    "# function relies on the globally defined documents variable.\n",
    "def idf(word):\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences\n",
    "\n",
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "\n",
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False)\n",
    " .head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "11     python  description  0.250000\n",
       "10      panda  description  0.250000\n",
       "9       using  description  0.250000\n",
       "8        hand  description  0.250000\n",
       "7       teach  description  0.250000\n",
       "4       skill  description  0.250000\n",
       "16   response      context  0.176471\n",
       "13         to      context  0.176471\n",
       "4      demand      context  0.176471\n",
       "3     created      context  0.176471\n",
       "2          wa      context  0.176471\n",
       "8        lack      context  0.176471\n",
       "10  percieved      context  0.176471\n",
       "7          of      context  0.176471\n",
       "12     talent      context  0.176471\n",
       "14    growing      context  0.176471\n",
       "15       that         news  0.166667\n",
       "10       they         news  0.166667\n",
       "2          18         news  0.166667\n",
       "3   announced         news  0.166667\n",
       "4          is         news  0.166667\n",
       "5        week         news  0.166667\n",
       "8        long         news  0.166667\n",
       "16       just         news  0.166667\n",
       "9        last         news  0.166667\n",
       "11        new         news  0.166667\n",
       "12         it         news  0.166667\n",
       "13   thursday         news  0.166667\n",
       "17   launched         news  0.166667\n",
       "3    codeup's  description  0.125000\n",
       "2         and  description  0.125000\n",
       "0     science      context  0.117647\n",
       "1        data      context  0.117647\n",
       "9         and      context  0.088235\n",
       "15   codeup's      context  0.088235\n",
       "5          in      context  0.088235\n",
       "5          on  description  0.083333\n",
       "6     program  description  0.083333\n",
       "1        data  description  0.083333\n",
       "0     science  description  0.083333\n",
       "6     program      context  0.058824\n",
       "11          a      context  0.058824\n",
       "1     program         news  0.055556\n",
       "14       data         news  0.055556\n",
       "7     science         news  0.055556\n",
       "6           a         news  0.055556\n",
       "0      codeup         news  0.055556"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = []\n",
    "\n",
    "# We'll caclulate the tf-idf value for every word across every document\n",
    "\n",
    "# Start by iterating over all the documents\n",
    "for doc, text in documents.items():\n",
    "    # We'll make a data frame that contains the tf for every word in every document\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)\n",
    "\n",
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the tf and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeup's</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup  codeup's  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x36 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = pd.read_csv('spam_clean.csv')\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.55%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   107\n",
      "spam          2   491\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.98      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.41%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    39\n",
      "spam         1   110\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.99      0.74      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam',\n",
       "       'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [0.95230689, 0.04769311],\n",
       "       [0.95230689, 0.04769311],\n",
       "       ...,\n",
       "       [0.95230689, 0.04769311],\n",
       "       [0.95230689, 0.04769311],\n",
       "       [0.95230689, 0.04769311]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3843,   16],\n",
       "       [ 229,  369]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      1.00      0.97      3859\n",
      "        spam       0.96      0.62      0.75       598\n",
      "\n",
      "    accuracy                           0.95      4457\n",
      "   macro avg       0.95      0.81      0.86      4457\n",
      "weighted avg       0.95      0.95      0.94      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.95\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00183806 0.00981146 0.         ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88912961, 0.11087039],\n",
       "       [0.86878971, 0.13121029],\n",
       "       [0.88689104, 0.11310896],\n",
       "       ...,\n",
       "       [0.88788542, 0.11211458],\n",
       "       [0.86500572, 0.13499428],\n",
       "       [0.88363421, 0.11636579]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3368    0]\n",
      " [ 532    0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      1.00      0.93      3368\n",
      "        spam       0.00      0.00      0.00       532\n",
      "\n",
      "    accuracy                           0.86      3900\n",
      "   macro avg       0.43      0.50      0.46      3900\n",
      "weighted avg       0.75      0.86      0.80      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.87\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3368    0]\n",
      " [ 122  410]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      3368\n",
      "        spam       1.00      0.77      0.87       532\n",
      "\n",
      "    accuracy                           0.97      3900\n",
      "   macro avg       0.98      0.89      0.93      3900\n",
      "weighted avg       0.97      0.97      0.97      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a3d07c6a0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
