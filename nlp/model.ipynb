{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    \"\"\"\n",
    "    Lowercase the string\n",
    "    Normalize unicode characters\n",
    "    Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    \"\"\"\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "     # remove anything not a space character, an apostrophy, letter, or number\n",
    "    string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "    \n",
    "    string = string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(s, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(s):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in s.split()]\n",
    "    string_of_lemmas = ' '.join(lemmas)\n",
    "    return string_of_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': \"Codeup's data science program was created in response to a \"\n",
      "            'percieved lack of data science talent, and growing demand.',\n",
      " 'description': \"Codeup's data science program teaches hands on skills using \"\n",
      "                'Python and pandas.',\n",
      " 'news': 'Codeup announced last thursday that they just launched a new data '\n",
      "         'science program. It is 18 weeks long.'}\n",
      "\n",
      "Cleaning and lemmatizing...\n",
      "\n",
      "{'context': \"codeup's data science program wa created in response to a \"\n",
      "            'percieved lack of data science talent and growing demand',\n",
      " 'description': \"codeup's data science program teach hand on skill using \"\n",
      "                'python and panda',\n",
      " 'news': 'codeup announced last thursday that they just launched a new data '\n",
      "         'science program it is 18 week long'}\n"
     ]
    }
   ],
   "source": [
    "documents = {\n",
    "    'news': 'Codeup announced last thursday that they just launched a new data science program. It is 18 weeks long.',\n",
    "    'description': 'Codeup\\'s data science program teaches hands on skills using Python and pandas.',\n",
    "    'context': 'Codeup\\'s data science program was created in response to a percieved lack of data science talent, and growing demand.'\n",
    "}\n",
    "pprint(documents)\n",
    "\n",
    "print('\\nCleaning and lemmatizing...\\n')\n",
    "\n",
    "documents = {topic: lemmatize(basic_clean(documents[topic])) for topic in documents}\n",
    "pprint(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idf\n",
       "word        \n",
       "teach    3.0\n",
       "created  3.0\n",
       "hand     3.0\n",
       "skill    3.0\n",
       "using    3.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple way to calculate idf for demonstration. Note that this\n",
    "# function relies on the globally defined documents variable.\n",
    "def idf(word):\n",
    "    n_occurences = sum([1 for doc in documents.values() if word in doc])\n",
    "    return len(documents) / n_occurences\n",
    "\n",
    "# Get a list of the unique words\n",
    "unique_words = pd.Series(' '.join(documents.values()).split()).unique()\n",
    "\n",
    "# put the unique words into a data frame\n",
    "(pd.DataFrame(dict(word=unique_words))\n",
    " # calculate the idf for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # sort the data for presentation purposes\n",
    " .set_index('word')\n",
    " .sort_values(by='idf', ascending=False)\n",
    " .head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>context</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>python</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>on</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>teach</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panda</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>using</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skill</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>program</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hand</td>\n",
       "      <td>description</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wa</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>program</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>response</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codeup's</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>growing</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>percieved</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>to</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lack</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>of</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>demand</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>created</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talent</td>\n",
       "      <td>context</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>week</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announced</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>last</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>they</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>just</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>long</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>that</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>launched</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thursday</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>science</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>codeup</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>program</td>\n",
       "      <td>news</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word          doc    tf_idf\n",
       "0     science      context  0.117647\n",
       "1        data      context  0.117647\n",
       "5        data  description  0.083333\n",
       "10        and  description  0.083333\n",
       "8      python  description  0.083333\n",
       "7          on  description  0.083333\n",
       "6       teach  description  0.083333\n",
       "11      panda  description  0.083333\n",
       "4    codeup's  description  0.083333\n",
       "3     science  description  0.083333\n",
       "2       using  description  0.083333\n",
       "1       skill  description  0.083333\n",
       "0     program  description  0.083333\n",
       "9        hand  description  0.083333\n",
       "4          wa      context  0.058824\n",
       "2     program      context  0.058824\n",
       "5    response      context  0.058824\n",
       "6    codeup's      context  0.058824\n",
       "7     growing      context  0.058824\n",
       "8   percieved      context  0.058824\n",
       "9          to      context  0.058824\n",
       "10       lack      context  0.058824\n",
       "11        and      context  0.058824\n",
       "12         in      context  0.058824\n",
       "13         of      context  0.058824\n",
       "14          a      context  0.058824\n",
       "15     demand      context  0.058824\n",
       "3     created      context  0.058824\n",
       "16     talent      context  0.058824\n",
       "1           a         news  0.055556\n",
       "17       week         news  0.055556\n",
       "2   announced         news  0.055556\n",
       "3         new         news  0.055556\n",
       "4        last         news  0.055556\n",
       "5          it         news  0.055556\n",
       "6        data         news  0.055556\n",
       "7        they         news  0.055556\n",
       "8        just         news  0.055556\n",
       "9        long         news  0.055556\n",
       "10         is         news  0.055556\n",
       "11         18         news  0.055556\n",
       "12       that         news  0.055556\n",
       "13   launched         news  0.055556\n",
       "14   thursday         news  0.055556\n",
       "15    science         news  0.055556\n",
       "16     codeup         news  0.055556\n",
       "0     program         news  0.055556"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = []\n",
    "\n",
    "# We'll caclulate the tf-idf value for every word across every document\n",
    "\n",
    "# Start by iterating over all the documents\n",
    "for doc, text in documents.items():\n",
    "    # We'll make a data frame that contains the tf for every word in every document\n",
    "    df = (pd.Series(text.split())\n",
    "          .value_counts()\n",
    "          .reset_index()\n",
    "          .set_axis(['word', 'raw_count'], axis=1, inplace=False)\n",
    "          .assign(tf=lambda df: df.raw_count / df.shape[0])\n",
    "          .drop(columns='raw_count')\n",
    "          .assign(doc=doc))\n",
    "    # Then add that data frame to our list\n",
    "    tfs.append(df)\n",
    "\n",
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the tf and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word</th>\n",
       "      <th>18</th>\n",
       "      <th>a</th>\n",
       "      <th>and</th>\n",
       "      <th>announced</th>\n",
       "      <th>codeup</th>\n",
       "      <th>codeup's</th>\n",
       "      <th>created</th>\n",
       "      <th>data</th>\n",
       "      <th>demand</th>\n",
       "      <th>growing</th>\n",
       "      <th>...</th>\n",
       "      <th>skill</th>\n",
       "      <th>talent</th>\n",
       "      <th>teach</th>\n",
       "      <th>that</th>\n",
       "      <th>they</th>\n",
       "      <th>thursday</th>\n",
       "      <th>to</th>\n",
       "      <th>using</th>\n",
       "      <th>wa</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>context</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word               18         a       and  announced    codeup  codeup's  \\\n",
       "doc                                                                        \n",
       "context      0.000000  0.058824  0.088235   0.000000  0.000000  0.088235   \n",
       "description  0.000000  0.000000  0.125000   0.000000  0.000000  0.125000   \n",
       "news         0.166667  0.055556  0.000000   0.166667  0.055556  0.000000   \n",
       "\n",
       "word          created      data    demand   growing  ...  skill    talent  \\\n",
       "doc                                                  ...                    \n",
       "context      0.176471  0.117647  0.176471  0.176471  ...   0.00  0.176471   \n",
       "description  0.000000  0.083333  0.000000  0.000000  ...   0.25  0.000000   \n",
       "news         0.000000  0.055556  0.000000  0.000000  ...   0.00  0.000000   \n",
       "\n",
       "word         teach      that      they  thursday        to  using        wa  \\\n",
       "doc                                                                           \n",
       "context       0.00  0.000000  0.000000  0.000000  0.176471   0.00  0.176471   \n",
       "description   0.25  0.000000  0.000000  0.000000  0.000000   0.25  0.000000   \n",
       "news          0.00  0.166667  0.166667  0.166667  0.000000   0.00  0.000000   \n",
       "\n",
       "word             week  \n",
       "doc                    \n",
       "context      0.000000  \n",
       "description  0.000000  \n",
       "news         0.166667  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll then concatenate all the tf values together.\n",
    "(pd.concat(tfs)\n",
    " # calculate the idf value for each word\n",
    " .assign(idf=lambda df: df.word.apply(idf))\n",
    " # then use the if and idf values to calculate tf-idf \n",
    " .assign(tf_idf=lambda df: df.idf * df.tf)\n",
    " .drop(columns=['tf', 'idf'])\n",
    " .sort_values(by='tf_idf', ascending=False)\n",
    " .pipe(lambda df: pd.crosstab(df.doc, df.word, values=df.tf_idf, aggfunc=lambda x: x))\n",
    " .fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x36 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(documents.values())\n",
    "tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = pd.read_csv('spam_clean.csv')\n",
    "df.head()\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.text)\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2)\n",
    "\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))\n",
    "\n",
    "lm = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "train['predicted'] = lm.predict(X_train)\n",
    "test['predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.49%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual      ham  spam\n",
      "predicted            \n",
      "ham        3857   110\n",
      "spam          2   488\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      3859\n",
      "        spam       1.00      0.82      0.90       598\n",
      "\n",
      "    accuracy                           0.97      4457\n",
      "   macro avg       0.98      0.91      0.94      4457\n",
      "weighted avg       0.98      0.97      0.97      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.41%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual     ham  spam\n",
      "predicted           \n",
      "ham        965    39\n",
      "spam         1   110\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       966\n",
      "        spam       0.99      0.74      0.85       149\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95292292, 0.04707708],\n",
       "       [0.95292292, 0.04707708],\n",
       "       [0.56756757, 0.43243243],\n",
       "       ...,\n",
       "       [0.95292292, 0.04707708],\n",
       "       [0.95292292, 0.04707708],\n",
       "       [0.95292292, 0.04707708]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3841,   18],\n",
       "       [ 232,  366]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      1.00      0.97      3859\n",
      "        spam       0.95      0.61      0.75       598\n",
      "\n",
      "    accuracy                           0.94      4457\n",
      "   macro avg       0.95      0.80      0.86      4457\n",
      "weighted avg       0.94      0.94      0.94      4457\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on test set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=3, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00183806 0.00981146 0.         ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88912961, 0.11087039],\n",
       "       [0.86878971, 0.13121029],\n",
       "       [0.88689104, 0.11310896],\n",
       "       ...,\n",
       "       [0.88788542, 0.11211458],\n",
       "       [0.86500572, 0.13499428],\n",
       "       [0.88363421, 0.11636579]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3368    0]\n",
      " [ 532    0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      1.00      0.93      3368\n",
      "        spam       0.00      0.00      0.00       532\n",
      "\n",
      "    accuracy                           0.86      3900\n",
      "   macro avg       0.43      0.50      0.46      3900\n",
      "weighted avg       0.75      0.86      0.80      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.87\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3368    0]\n",
      " [ 122  410]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      3368\n",
      "        spam       1.00      0.77      0.87       532\n",
      "\n",
      "    accuracy                           0.97      3900\n",
      "   macro avg       0.98      0.89      0.93      3900\n",
      "weighted avg       0.97      0.97      0.97      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a3b6c5908>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
